export const meta = {
  id: "dbt",
  title: "dbt"
};

The recommended way of building Splitgraph data images is [Splitfiles](../concepts/splitfiles) that offer Dockerfile-like caching, provenance tracking and efficient rebuilds.

However, there are plenty of other great tools for building datasets and, as long as they work with PostgreSQL, they too can benefit from Splitgraph's data versioning, packaging and sharing capabilities.

One such tool is [dbt](https://getdbt.com) that assembles data transformations from small building blocks, decreasing the amount of boilerplate. In a sense, dbt can be used as an advanced SQL templating engine.

Turning the source and the target schemas that dbt uses into Splitgraph repositories opens up a lot of opportunities:

* No need to run development and production dbt models against the same warehouse. A Splitgraph image can be cloned and checked out on the development engine.
* Performing what-if analyses becomes simple by switching between different versions of the source dataset and comparing the resultant images with [`sgr diff`](../sgr/image_information/diff).
* Built datasets can be pushed to other Splitgraph engines, shared publicly or serve as inputs to a pipeline of Splitfiles.
* Input datasets can leverage Splitgraph's [layered querying](../large_datasets/layered_querying),
    allowing dbt to seamlessly query huge datasets with a limited amount of local disk space.

## Example

The [dbt example](https://github.com/splitgraph/splitgraph/tree/v0.1.0/examples/dbt) showcases
running dbt against the Splitgraph engine, using Splitgraph to swap between different versions of the
source dataset and looking at their effect on the built dbt model.

<cast src="@splitgraph/content/casts/versioned/latest/dbt.cast" />