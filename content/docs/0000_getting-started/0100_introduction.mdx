export const meta = {
  id: "introduction",
  title: "Welcome to Splitgraph",
};

Splitgraph is a data management, building and sharing tool inspired by Docker and Git that works on top of PostgreSQL and integrates seamlessly with anything that uses PostgreSQL.

Splitgraph allows the user to manipulate [data images](../concepts/images) (snapshots of SQL tables at a given point in time) as if they
were code repositories by versioning, pushing and pulling them. It brings the best parts of Git and Docker, tools well-known and loved by developers, to data science and data engineering, and allows users to build and manipulate datasets directly on their database using familiar commands and paradigms.

It works on top of PostgreSQL and uses SQL for all versioning and internal operations. You can "check out" data into actual PostgreSQL tables, offering read/write performance and feature parity with PostgreSQL and allowing you to query it with any SQL client. The client application has no idea that it's talking to a Splitgraph table and you don't need to rewrite any of your tools to use Splitgraph. Anything that works with PostgreSQL will work with Splitgraph.

Splitgraph also defines the [declarative Splitfile language](../concepts/splitfiles) with Dockerfile-like caching semantics that allows you to build Splitgraph data images in a composable, maintainable and reproducible way. When you build data with Splitfiles, you get [provenance tracking](../working-with-data/inspecting-provenance). You can inspect an image's metadata to find the exact upstream images, tables and columns that went into it. With one command, Splitgraph can use this provenance data to rebuild an image against a newer version of its upstream dependencies. You can easily integrate Splitgraph into your existing CI pipelines, to keep your data up-to-date and stay on top of changes to its inputs.

You do not need to download the full Splitgraph image to query it. Instead, you can query Splitgraph images with [layered querying](../large-datasets/layered-querying), which will download only the regions of the table relevant to your query, using bloom filters and other metadata. This is useful when you're exploring large datasets from your laptop, or when you're only interested in a subset of data from an image. This is still completely transparent to the client application, which sees a PostgreSQL schema that it can talk to using the Postgres wire protocol.

Splitgraph does not limit your data sources to Postgres databases. It includes first-class support for importing and querying data from other databases using Postgres [foreign data wrappers](../ingesting-data/foreign-data-wrappers/introduction). You can create Splitgraph images or query data in [MongoDB](../ingesting-data/foreign-data-wrappers/load-mongo-collections),
[MySQL](../ingesting-data/foreign-data-wrappers/load-mysql-tables),
[CSV files](../ingesting-data/load-csv-files) or [other Postgres databases](../ingesting-data/foreign-data-wrappers/load-postgres-tables) using the same interface.

Splitgraph is peer-to-peer, and you can share images with other Splitgraph installations. [Splitgraph Cloud](../splitgraph-cloud/introduction) acts as a remote Splitgraph peer, and also provides a lot of scalability and bonus features. When you push a dataset to Splitgraph Cloud, it gets extra perks like an OpenAPI-compatible [REST endpoint](../splitgraph-cloud/publish-rest-api) (more perks coming soon!). Splitgraph Cloud also acts as a catalog for external data, indexing over 40000 open government datasets on the [Socrata platform](https://www.tylertech.com/products/socrata). Analyze [coronavirus data](https://www.splitgraph.com/cdc-gov/provisional-covid19-death-counts-by-sex-age-and-9bhg-hcku) with Jupyter and scikit-learn, plot nearby [marijuana dispensaries](https://www.splitgraph.com/colorado-gov/licensed-marijuana-businesses-in-colorado-sqs8-2un5) with Metabase and PostGIS or just explore [Chicago open data ](https://www.splitgraph.com/docs/ingesting-data/socrata) with DBeaver and do so from the comfort of a battle-tested RDBMS with a mature feature set and a rich ecosystem of integrations.
